{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Prova Final - Cdados 2019.2\n",
    "AULA 20 para frente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ bibliotecas ------------\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import probplot, t, norm \n",
    "from math import sqrt\n",
    "%matplotlib inline\n",
    "\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# TLC \n",
    "\n",
    "ESTUDAR \n",
    "\n",
    "----\n",
    "# Tstudent e teste normal diferen√ßa\n",
    "* $sigma^2$ desconheicodo X (popula√ß√£o) normal -- T Student\n",
    "* $sigma^2$ conhecido - teste normal\n",
    "\n",
    "---\n",
    "---\n",
    "# F√≥rmulas:\n",
    "* **Esperan√ßa**:\n",
    "\n",
    "* **Vari√¢ncia esperada**:\n",
    "$$Var(Ax+by)=a^2V(x)+b^2V(y)+2abCov(X,Y)$$\n",
    "\n",
    "\n",
    "*  **F√≥rmula de padroniza√ß√£o da normal de uma distribui√ß√£o amostral**\n",
    "\n",
    "    $$Z = \\frac{(\\bar{X}-u)}{\\frac{desviopadr√£o}{n^(1/2)}}$$\n",
    "    * Gama seria a certeza que queremos \n",
    "    * o Z seria os dois pontos que cerca a m√©dia \n",
    "        * $-Z_(\\frac{gama}{2})$ e $ponto +Z_(\\frac{gama}{2})$\n",
    "    * Achamos a -Zgama/2 = norm.ppf(0.5-gama/2)\n",
    "    * Achamos a +Zgama/2 = norm.ppf(0.5+gama/2)\n",
    "    * $n = \\left( z_{\\gamma/2} \\cdot \\frac{\\sigma}{d}\\right)^2$\n",
    "    * (ultimo ex da aps)\n",
    "---\n",
    "---\n",
    "# Encontrando $\\hat{\\beta_{1}}$ e $\\hat{\\beta_{0}}$\n",
    "## Formula:\n",
    "* $\\hat{\\beta_{0}}$:\n",
    "$$\\hat{\\beta_{0}} = \\bar{y} - \\hat{\\beta_1} \\bar{x}$$\n",
    "\n",
    "* $\\hat{\\beta_{1}}$:\n",
    "\n",
    "$$\\hat{\\beta_1}= \\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\sum\\limits_{i=1}^{n}(x_{i}-\\bar{x})^2} = \\frac{S_{xy}}{S_{xx}} $$\n",
    "\n",
    "F√≥rmula alternativa que pode ser √∫til:\n",
    "\n",
    "\n",
    "$$\\hat{\\beta}_1 = \\frac{Cov(X,Y)}{Var(X)}$$\n",
    "\n",
    "\n",
    "* $SS_E$ \n",
    "    * (SQRes) A soma dos quadrados dos res√≠duos\n",
    "$$SQRes=SS_{E}=\\sum\\limits^{n}_{i=1}(y_i-\\hat{y}_i)^2=\\sum\\limits_{i=1}^{n}\\epsilon^2_{i}$$\n",
    "\n",
    "\n",
    "* $SQT$\n",
    "    * Tamb√©m chamado de $SS_T$ no livro, que √© a **soma dos quadrados totais**:\n",
    "$$SQT=SS_{T}=\\sum\\limits^{n}_{i=1}(y_i-\\bar{y})^2$$\n",
    "\n",
    "* $R^2$\n",
    "$$ R^2 = 1 - \\frac{SS_E}{SS_T} = \\frac{SS_R}{SS_T}$$\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso tenha duas listas transformar em um array pra fazer calculos futuros\n",
    "valor_x = [1, 51, 13, 41,21,123]\n",
    "valor_y = [1, 51, 13, 41,21,123]\n",
    "\n",
    "x = np.array(valor_x)\n",
    "y = np.array(valor_y)\n",
    "\n",
    "x_ = np.mean(x)\n",
    "y_ = np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de Beta1:  1.0\n",
      "Valor de Beta0:  40.666666666666664\n"
     ]
    }
   ],
   "source": [
    "Sxy = np.sum((x - x_)*(y - y_)) # note que as opera√ß√µes s√£o feitas em cada elemento dos arrays x e y\n",
    "Sxx = np.sum((x-x_)**2)\n",
    "beta_1 = Sxy/Sxx\n",
    "beta_zero = y_ - beta_1\n",
    "print(\"Valor de Beta1: \",beta_1)\n",
    "print(\"Valor de Beta0: \",beta_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSE = reg.ssr #lembrando que reg seria uma variavel definida da fun√ß√£o que faz a regress√£o\n",
    "# print(\"Valor do SSE: \",SSE)\n",
    "# SQT = np.sum((y-y_)**2)\n",
    "# print(\"Valor SQT: \",SQT)\n",
    "\n",
    "## APS6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fazendo uma regress√£o linear Parte1 \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liu\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\stattools.py:71: ValueWarning: omni_normtest is not valid with less than 8 observations; 6 samples were given.\n",
      "  \"samples were given.\" % int(n), ValueWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.845e+32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Nov 2019</td> <th>  Prob (F-statistic):</th> <td>1.76e-64</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:26:52</td>     <th>  Log-Likelihood:    </th> <td>  188.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     6</td>      <th>  AIC:               </th> <td>  -372.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     4</td>      <th>  BIC:               </th> <td>  -372.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-5.329e-15</td> <td> 4.25e-15</td> <td>   -1.253</td> <td> 0.278</td> <td>-1.71e-14</td> <td> 6.48e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.0000</td> <td> 7.36e-17</td> <td> 1.36e+16</td> <td> 0.000</td> <td>    1.000</td> <td>    1.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.414</td> <th>  Prob(JB):          </th> <td>   0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.500</td> <th>  Cond. No.          </th> <td>    83.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 1.845e+32\n",
       "Date:                Sun, 24 Nov 2019   Prob (F-statistic):           1.76e-64\n",
       "Time:                        13:26:52   Log-Likelihood:                 188.08\n",
       "No. Observations:                   6   AIC:                            -372.2\n",
       "Df Residuals:                       4   BIC:                            -372.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -5.329e-15   4.25e-15     -1.253      0.278   -1.71e-14    6.48e-15\n",
       "x1             1.0000   7.36e-17   1.36e+16      0.000       1.000       1.000\n",
       "==============================================================================\n",
       "Omnibus:                          nan   Durbin-Watson:                   0.288\n",
       "Prob(Omnibus):                    nan   Jarque-Bera (JB):                2.062\n",
       "Skew:                          -1.414   Prob(JB):                        0.357\n",
       "Kurtosis:                       3.500   Cond. No.                         83.4\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regress(X,Y):\n",
    "    X_cp = sm.add_constant(X)\n",
    "    model = sm.OLS(Y,X_cp)\n",
    "    results = model.fit()\n",
    "    return results\n",
    "\n",
    "reg = regress(x, y) # DESCOMENTE a linha para funcionar\n",
    "reg.summary() # DESCOMENTE a linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betas do Statsmodels - Beta 0: -5.329070518200751e-15   Beta 1 1.0:\n"
     ]
    }
   ],
   "source": [
    "beta0s = reg.params[0] # como acessar o beta 0 calculado\n",
    "beta1s = reg.params[1] # como acessar o beta 1 e assim por diante\n",
    "print(\"Betas do Statsmodels - Beta 0: {:}   Beta 1 {:}:\".format(beta0s, beta1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fazendo Regress√£o Linear parte: 2  - sklearn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#model = LinearRegression().fit(X_train,y_train)\n",
    "#y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Como analisar a regress√£o linear \n",
    "* *$R^2$:* Este valor √© uma medida de ajustamento de um modelo estat√≠stico linear generalizado varia entre 0 e 1, indicando, em percentagem, o quanto o modelo consegue explicar os valores observados. Quanto maior o R¬≤, mais explicativo √© o modelo, melhor ele se ajusta √† amostra.\n",
    "* **Coef:** s√£o os coeficientes da regress√£o linear, o **coef const** √© o H0\n",
    "* **Pvalue:** Este valor varia de 0 a 1, quanto mais proximo do 0 mais correlacionado s√£o os dados\n",
    "* **F-statistic:** Seria uma jun√ß√£o dos Pvalue\n",
    "    * Testa as seguintes hip√≥teses:\n",
    "        * H0:Œ≤1=Œ≤2=‚Ä¶=Œ≤p=0\n",
    "        * H1:Œ≤i‚â†0 para no m√≠nimo algum  i, com  i=1,‚Ä¶,n\n",
    " \n",
    "    * A rejei√ß√£o da hip√≥tese nula implica que no m√≠nimo uma vari√°vel explicativa (regressora) contruibui significantemente para o modelo. Esse teste F √© mais √∫til no caso de modelo de regress√£o m√∫ltipla.\n",
    "* **Durbin-Watson:** √© utilizado para detectar a presen√ßa de autocorrela√ß√£o (depend√™ncia) nos res√≠duos de uma an√°lise de regress√£o. Ele varia de 0 a 4, sendo que de 0 a 2 indica que h√° uma autocorrela√ß√£o positiva e de 2 a 4 indica uma autocorrela√ß√£o negativa. \n",
    "    * Um valor pr√≥ximo de  2 sugere que n√£o h√° autocorrela√ß√£o dos res√≠duos\n",
    "    * Um valor menor que  2 sugere correla√ß√£o positiva dois res√≠duos\n",
    "    * Um valor maior que  2 sugere correla√ß√£o negativa dois res√≠duos\n",
    "* **Omnibus:** testa a normalidade dos residuos\n",
    "* **Prob(Omnibus):** for muito baixo, existe evid√™ncia de que os res√≠duos n√£o s√£o distribu√≠dos normalmente, violando nesse caso a suposi√ß√£o do modelo de regress√£o.\n",
    "    * Caso o enunciado n√£o dizer nada, se a probabilidade de ombibus for maior que 5% j√° podemos concluir que segue uma distribui√ß√£o normal\n",
    "* **JB**: testa a normalidade dos residuos\n",
    "* **Prob(JB):** for muito baixo, existe evid√™ncia de que os res√≠duos n√£o s√£o distribu√≠dos normalmente, violando nesse caso a suposi√ß√£o do modelo de regress√£o.\n",
    "\n",
    "**obs:** Gabarito aula 25 regress√£o linear simples explica os testes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Teste de hipotese \n",
    "* Fazemos com o par√¢metro populacional e n√£o a m√©dia amostral\n",
    "\n",
    "* MIN PREENCHE \n",
    "\n",
    "\n",
    "# Erro tipo 1 e tipo 2\n",
    "|       |H0 √© verdadeiro|H0 √© falso|\n",
    "|:---|:-----|:-----|\n",
    "|Rejeito H0| Erro tipo 1,Falso Positivo eProbabilidade ùõº|Decis√£o correta|  \n",
    "|N√£o rejeito H0|Decis√£o correta| Erro tipo 2, Falso Negativo e Probabilidade ùõΩ|\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Matriz de confus√£o\n",
    "* Matriz pra acuracia de um classificador \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Socrative\n",
    "# Pergunta 1\n",
    "\n",
    "* $E_X1 = 5$\n",
    "* $V_Z1 = 100$\n",
    "* $Antes = Y = X1+X2$\n",
    "* $depois = W =2X1 $\n",
    "* $E(Y) = E(X1)+E(X2) = 10$ \n",
    "* $Var(Y) = Var(X1)+ Var(X2) = 200$\n",
    "* $E(W) = E(2X1) = 2E(X1)$\n",
    "* $V(W) = 4Var(X1) = 400$\n",
    "\n",
    "* Logo a Variabilidade aumenta e n√£o mudaria o processo\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
